{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5\n",
    "If your environment got too slow and unwieldy, part 5 is extracted by itself to build a new notebook with a long NDVI time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.plot import show, reshape_as_image\n",
    "from pyproj import Transformer\n",
    "from satsearch import Search\n",
    "import numpy.ma as ma\n",
    "from rasterio import features\n",
    "import geopandas \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Sentinel-2 STAC API\n",
    "url = \"https://earth-search.aws.element84.com/v0/\"\n",
    "\n",
    "# Bounding Box delineating the spatial extent for NDVI mapping\n",
    "bbox = [-110.74772571639987, 32.270431012618026, -110.70996215904789, 32.29386169894274]\n",
    "\n",
    "# The date range for mapping NDVI overtime\n",
    "date_range = \"2021-07-05/2021-08-02\"\n",
    "\n",
    "def image_search(bbox, date_range, scene_cloud_tolerance):\n",
    "    \"\"\"\n",
    "    Using SatSearch find all Sentinel-2 images\n",
    "    that meet our criteria\n",
    "    \"\"\"\n",
    "    \n",
    "    search = Search(\n",
    "        bbox=bbox,\n",
    "        datetime=date_range,\n",
    "        query={\n",
    "            \"eo:cloud_cover\": {\"lt\": scene_cloud_tolerance}\n",
    "        },  \n",
    "        collections=[\"sentinel-s2-l2a-cogs\"],\n",
    "        url=url,\n",
    "    )\n",
    "\n",
    "    return search.items()\n",
    "\n",
    "transform_window = None\n",
    "def range_request(image_url, bbox):\n",
    "    \"\"\"\n",
    "    Request and read just the required pixels from the COG\n",
    "    \"\"\"\n",
    "    \n",
    "    with rasterio.open(image_url) as src:\n",
    "        coord_transformer = Transformer.from_crs(\"epsg:4326\", src.crs)\n",
    "        # calculate pixels to be streamed from the COG\n",
    "        coord_upper_left = coord_transformer.transform(bbox[3], bbox[0])\n",
    "        coord_lower_right = coord_transformer.transform(bbox[1], bbox[2])\n",
    "        pixel_upper_left = src.index(coord_upper_left[0], coord_upper_left[1])\n",
    "        pixel_lower_right = src.index(coord_lower_right[0], coord_lower_right[1])\n",
    "         \n",
    "                \n",
    "        # request only the bytes in the window\n",
    "        window = rasterio.windows.Window.from_slices(\n",
    "            (pixel_upper_left[0], pixel_lower_right[0]),\n",
    "            (pixel_upper_left[1], pixel_lower_right[1]),\n",
    "        )\n",
    "\n",
    "        # The affine transform - This will allow us to \n",
    "        # translate pixels coordiantes back to geospatial coordiantes\n",
    "        transform_window = rasterio.windows.transform(window,src.transform)\n",
    "        \n",
    "        bands = 1\n",
    "        if \"TCI\" in image_url: # aka True Colour Image aka RGB\n",
    "            bands = [1, 2, 3]\n",
    "\n",
    "        subset = src.read(bands, window=window)\n",
    "        return(subset, transform_window)\n",
    "\n",
    "\n",
    "\n",
    "fields = geopandas.read_file('neighborhood_samples.geojson').to_crs(epsg=32612)\n",
    "\n",
    "\n",
    "def mask_ndvi_by_field(image, field_geom):\n",
    "    \"\"\"\n",
    "    returns a numpy mask\n",
    "    \"\"\"\n",
    "    mask = features.geometry_mask(field_geom, \n",
    "                                out_shape=(image['ndvi'].shape[0],  image['ndvi'].shape[1]),\n",
    "                                transform=image['transform_window'], \n",
    "                                all_touched=False, \n",
    "                                invert=False)\n",
    "    ndvi_masked = ma.masked_array(image['ndvi'], mask)\n",
    "    return ndvi_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: NDVI Time Series \n",
    "\n",
    "Finally we are going to calculate the average NDVI within one of the polygons over a lengthy time period.\n",
    "\n",
    "First we will re-search but for a longer time period. This is largely a copy-paste from earlier in this notebook but expediting the imagery for having NDVI for the full time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The date range for mapping NDVI overtime\n",
    "date_range = \"2020-01-01/2021-12-31\"\n",
    "\n",
    "\n",
    "\n",
    "long_series_images = []\n",
    "items = image_search(bbox, date_range, 5)\n",
    "items.summary()\n",
    "\n",
    "rgb = items[0].asset(\"visual\")[\"href\"]\n",
    "rgb_subset, transform_window = range_request(rgb, bbox)\n",
    "\n",
    "for item in items:\n",
    "    \n",
    "    # Refs to long_series_images\n",
    "    red = item.asset(\"red\")[\"href\"]\n",
    "    nir = item.asset(\"nir\")[\"href\"]\n",
    "    date = item.date.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    # Streamed pixels within bbox\n",
    "    red_subset, transform_window = range_request(red, bbox)\n",
    "    nir_subset, transform_window = range_request(nir, bbox)\n",
    "\n",
    "    # Calculate NDVI\n",
    "    ndvi_subset = (nir_subset.astype(float) - red_subset.astype(float)) / (\n",
    "        nir_subset + red_subset\n",
    "    )\n",
    "    \n",
    "    # Store the data for further processing\n",
    "    long_series_images.append(\n",
    "        {\"date\": date, \"ndvi\": ndvi_subset,'transform_window': transform_window}\n",
    "    )\n",
    "\n",
    "# reverse list as to be oldest to newest\n",
    "long_series_images.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(long_series_images))\n",
    "print(long_series_images[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, subset the data by masking by each \"field\". In this case we are going to add a new entry to each of the `long_series_image` `dict`s containing an `ndvi_fields` as a key. This will resolve to another `dict` containing keys for all the different values of the `area` column in the `GeopandasDataFrame` that we downloaded for our \"fields\". The choice of `area` as an attribute name was probably a poor choice. It's a text field with values like \"riparian\" and \"hood\". Thus, each element of `image['ndvi_fields']` will have the masked NDVI data for that date and that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in long_series_images:\n",
    "    ndvi_fields = {}\n",
    "    \n",
    "    for index, row in fields.iterrows():\n",
    "        field_mask = mask_ndvi_by_field(image,row.geometry)\n",
    "        ndvi_fields[row.area] = field_mask\n",
    "        image['ndvi_fields'] = ndvi_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "items = image_search(bbox, date_range, 5)\n",
    "\n",
    "rgb = items[0].asset(\"visual\")[\"href\"]\n",
    "rgb_subset, transform_window = range_request(rgb, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use geopandas `loc` to select the field where field_id == 6\n",
    "riparian = fields.loc[fields['area'] == 'riparian']\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(12,12))\n",
    "    \n",
    "rgb_axes = show(rgb_subset,\n",
    "                transform=transform_window, \n",
    "                ax=ax,\n",
    "                alpha=.75,\n",
    "                cmap=\"RdYlGn\", \n",
    "                title=\"Field 6\")\n",
    "fields.boundary.plot(ax=ax, color='skyblue', linewidth=4)\n",
    "riparian.boundary.plot(ax=ax, color='yellow', linewidth=6)                             \n",
    "rgb_axes.ticklabel_format(style ='plain') # show full y-coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally... This is where we graph the NDVI over one of our polygon features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = np.array([long_series_images[i]['date'] for i in range(len(long_series_images))])\n",
    "ndvi_values = np.array([long_series_images[i]['ndvi_fields'][\"riparian\"].mean() for i in range(len(long_series_images))])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "ax.plot_date(dates, ndvi_values, marker='', linestyle='-')\n",
    "fig.autofmt_xdate()\n",
    "fig.suptitle('Mean NDVI for Riparian (2020-2021)', fontsize=24)\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Mean NDVI', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable 5 - `ndvi-time-series.png`\n",
    "\n",
    "Save a screenshot of the time series graph above as `ndvi-time-series.png`\n",
    "\n",
    "## Final Deliverables\n",
    "Submit an open pull request from the `rasterio` branch to be merged with `master` containing these 5 files. Do not merge your pull request. \n",
    "- `stac-items.png`\n",
    "- `image-numpy.png`\n",
    "- `image-plots.png`\n",
    "- `fields.png`\n",
    "- `ndvi-time-series.png`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6970b9bc1f22c1555ce2e3aef3e9bc8c56c5727cd75cae357902c75ead4068e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
