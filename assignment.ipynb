{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "In this assignment you will learn about the `rasterio` library and interact with Sentinel scenes in an AWS cloud bucket. You will also learn about Cloud-Optimized Geotiffs (COGs) and the Spatio-Temporal Asset Catalog (STAC) specification.\n",
    "\n",
    "## Background\n",
    "You have learned how to use the `geopandas` library to interact with geospatial vector data. The next step is to interact with raster data. The primary library that we use for raster is `rasterio`.Due to the nature of raster datasets and, in large part because of continous earth observation from satellites, a number of standards and technologies have built around optimizing finding raster datasets and utilizing subsets of raster datasets without necessitating the download of copious amounts of imagery that end users have no interest in. The main concepts we will talk about here are Cloud-Optimized Geotiffs, or COGs, windowed reads, and the Spatio-Temporal Asset Catalog (STAC) standard for searching for satellite imagery and other spatio-temporal data.\n",
    "\n",
    "Background reading:\n",
    "- COGs\n",
    "  - https://developers.planet.com/docs/planetschool/an-introduction-to-cloud-optimized-geotiffs-cogs-part-1-overview/\n",
    "- Rasterio\n",
    "  - Windows Reading: https://rasterio.readthedocs.io/en/latest/topics/windowed-rw.html\n",
    "- STAC\n",
    "  - Intro to STAC: https://stacspec.org/en/tutorials/intro-to-stac/\n",
    "  - About STAC: https://stacspec.org/en/about/stac-spec/ \n",
    "\n",
    "## Housekeeping\n",
    "### Learning Objectives\n",
    "1) Become familiar with python libraries: `rasterio` and `satsearch`.\n",
    "2) Learn about Cloud-Optimized Geotiffs (COGs)\n",
    "3) Learn about Spatio-Temporal Asset Catalogs (STACs)\n",
    "\n",
    "### Administrative Needs\n",
    "1) Configure this Notebook to use the new conda environment for its kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setting up the python environment\n",
    "Open this file (`assignment.ipynb`) in the Editor\n",
    "\n",
    "A dialog should pop-up asking you to install recommended `Python` and `Jupyter` extensions.\n",
    "\n",
    "![vscode-install-extensions.png](./media/vscode-install-extensions.png)\n",
    "\n",
    "Click on the kernel selector at the top right hand corner of the Jupyter Notebook in the `Editor` panel.\n",
    "\n",
    "![select-kernel.png](./media/select-kernel.png)\n",
    "\n",
    "and select the `geo-python-38` item.\n",
    "\n",
    "![select-geo-python-kernel.png](./media/select-geo-python-kernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walking through this notebook\n",
    "\n",
    "Congratulations! You now have a Jupyter Notebook running in a cloud environment with geospatially-enabled python. The rest of this tutorial will focus on the content (Finally!)\n",
    "\n",
    "This is adapted from Simon Planzer's tutorial on [NDVI Time Series with COGs](https://www.simonplanzer.com/articles/cog-ndvi-part1/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Finding imagery with STAC\n",
    "\n",
    "The first step is to import our needed libraries and initialize some global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.plot import show, reshape_as_image\n",
    "from pyproj import Transformer\n",
    "from satsearch import Search\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Sentinel-2 STAC API\n",
    "url = \"https://earth-search.aws.element84.com/v0/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will search the STAC catalog for `sentinel-s2-l2a-cogs`. For more about what data is returned from a STAC query, see [STAC specification](https://stacspec.org/en/about/stac-spec/). Essentially it is a list of STAC items and possibly additional STAC catalogs, allowing a hierarchical grouping of STAC items. Here we are only interested in the `items` which will contain a `href`, or a link to where can find the data. Since the collection we are searching _only_ contains COGs we will be able to read the data from within a small Jupyter notebook.\n",
    "\n",
    "There is a python library, `satsearch` that handles a lot of this for us, and we are going to wrap that in a helper function that takes a bounding box, date range, and cloud tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_search(bbox, date_range, scene_cloud_tolerance):\n",
    "    \"\"\"\n",
    "    Using SatSearch find all Sentinel-2 images\n",
    "    that meet our criteria\n",
    "    \"\"\"\n",
    "    \n",
    "    search = Search(\n",
    "        bbox=bbox,\n",
    "        datetime=date_range,\n",
    "        query={\n",
    "            \"eo:cloud_cover\": {\"lt\": scene_cloud_tolerance}\n",
    "        },  \n",
    "        collections=[\"sentinel-s2-l2a-cogs\"],\n",
    "        url=url,\n",
    "    )\n",
    "\n",
    "    return search.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define some constants for our search. You could modify these to your own choosing if you want. The settings below are for a couple of summer scenes in the mountains east of Tucson, AZ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding Box delineating the spatial extent for NDVI mapping\n",
    "bbox = [-110.74772571639987, 32.270431012618026, -110.70996215904789, 32.29386169894274]\n",
    "\n",
    "# The date range for mapping NDVI overtime\n",
    "date_range = \"2021-07-05/2021-08-02\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we search the catalog using our helper function. The `items.summary()` prints a summary of what we found in our search. Note that STAC does not include data; just metadata about the scenes, including where we can access the actual image data. For a more thorough discussion and walkthrough of STAC catalog items, see https://github.com/sat-utils/sat-stac/blob/master/tutorial-2.ipynb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's search for imagery in our area and time range, then print a summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = image_search(bbox, date_range, 5)\n",
    "items.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`items.summary()` gives a brief description of what we have; namely, the names of the items. Let's look at an individual item more closely.\n",
    "\n",
    "## Deliverable 1: `stac-items.png`\n",
    "Take a screenshot of this page showing the output of `items.summary()` and save it as `stac-items.png`. You can upload it directly in the `Explorer` panel. Right click on the space below the file list and select \"Upload\"\n",
    "\n",
    "![upload-screenshot.png](./media/upload-screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick one item from the catalog and look at some of its properties. This will show its bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = items[0]\n",
    "print(item.bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at a few more properties of the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(item.geometry)\n",
    "print(\"-\")\n",
    "print(item.datetime)\n",
    "print(\"-\")\n",
    "print(item.date)\n",
    "print(\"-\")\n",
    "print(item.assets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those `assets` are a little hard to read. Let's see what it is and how we can interact with it better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(item.assets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's a `dict` that means it has `.keys()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.assets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like satellite image bands and some additional rasters like a thumbnail, an overview, and a visual product plus water vapor clouds, etc. Let's see what we have for the `visual` asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.assets[\"visual\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `href` entry which contains an obvious link to data. For fun, you can copy that URL and open it in QGIS with `Layer` -> `Add Layer` -> `Add Raster Layer` and enter the URL of the scene.\n",
    "\n",
    "Meanwhile, let's see what other metadata this item has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in item.properties:\n",
    "    print('%s: %s' % (key, item.properties[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Reading COGs\n",
    "\n",
    "Ok, that's enough messing around. Let's go play with the data. Performing windowed reads is not the most straightforward so we will use a helper function to abstract away some of the details about the window so we can just pass in the image url and the bounding box. This function will make a windowed read from the remote COG based on some url and return the image pixel data as a `numpy.ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_window = None\n",
    "def range_request(image_url, bbox):\n",
    "    \"\"\"\n",
    "    Request and read just the required pixels from the COG\n",
    "    \"\"\"\n",
    "    \n",
    "    with rasterio.open(image_url) as src:\n",
    "        coord_transformer = Transformer.from_crs(\"epsg:4326\", src.crs)\n",
    "        # calculate pixels to be streamed from the COG\n",
    "        coord_upper_left = coord_transformer.transform(bbox[3], bbox[0])\n",
    "        coord_lower_right = coord_transformer.transform(bbox[1], bbox[2])\n",
    "        pixel_upper_left = src.index(coord_upper_left[0], coord_upper_left[1])\n",
    "        pixel_lower_right = src.index(coord_lower_right[0], coord_lower_right[1])\n",
    "         \n",
    "                \n",
    "        # request only the bytes in the window\n",
    "        window = rasterio.windows.Window.from_slices(\n",
    "            (pixel_upper_left[0], pixel_lower_right[0]),\n",
    "            (pixel_upper_left[1], pixel_lower_right[1]),\n",
    "        )\n",
    "\n",
    "        # The affine transform - This will allow us to \n",
    "        # translate pixels coordiantes back to geospatial coordiantes\n",
    "        transform_window = rasterio.windows.transform(window,src.transform)\n",
    "        \n",
    "        bands = 1\n",
    "        if \"TCI\" in image_url: # aka True Colour Image aka RGB\n",
    "            bands = [1, 2, 3]\n",
    "\n",
    "        subset = src.read(bands, window=window)\n",
    "        return(subset, transform_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it into action using the first item in the list we got back from STAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = items[0].asset(\"red\")[\"href\"]\n",
    "img_sub, transform_window = range_request(img, bbox)\n",
    "print(type(img_sub))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show that it really is pixel data, look at the `img_sub` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable 2: `image-numpy.png`\n",
    "\n",
    "Take a screenshot of the output above showing your `array([[[...` and name it `image-numpy.png`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Calculate NDVI for scene subsets\n",
    "This next part is going to calculate NDVI for the windowed area for all the scenes in our `items` list. For each one it will read the `href` dict entry for the `red`, `nir`, and `visual` assets. Then it will download the image subset using the windowed read from `rasterio`, and then it will save the data in a list named `images`. \n",
    "\n",
    "_Note: This step can take longer than a minute_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images= []\n",
    "\n",
    "for item in items:\n",
    "    \n",
    "    # Refs to images\n",
    "    red = item.asset(\"red\")[\"href\"]\n",
    "    nir = item.asset(\"nir\")[\"href\"]\n",
    "    rgb = item.asset(\"visual\")[\"href\"]\n",
    "    date = item.date.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    # Streamed pixels within bbox\n",
    "    red_subset, transform_window = range_request(red, bbox)\n",
    "    nir_subset, transform_window = range_request(nir, bbox)\n",
    "    rgb_subset, transform_window = range_request(rgb, bbox)\n",
    "\n",
    "    # Calculate NDVI\n",
    "    ndvi_subset = (nir_subset.astype(float) - red_subset.astype(float)) / (\n",
    "        nir_subset + red_subset\n",
    "    )\n",
    "    \n",
    "    # Store the data for further processing\n",
    "    images.append(\n",
    "        {\"date\": date, \"rgb\": rgb_subset, \"ndvi\": ndvi_subset,'transform_window': transform_window}\n",
    "    )\n",
    "\n",
    "# reverse list as to be oldest to newest\n",
    "images.reverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was fun but what do we have? Let's take a look by using the `show()` function from `rasterio` to view the imagery. Note that this step has often crashed my kernel, in which case you'll need to start over from **Walking through this notebook**. This is the price of using free cloud resources. This would be more stable on a desktop computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualise NDVI and RBG images Side by Side\n",
    "num_images = len(images)\n",
    "width, height = 10, num_images * 4.5\n",
    "\n",
    "fig, subplots = plt.subplots(\n",
    "    len(images),\n",
    "    2,\n",
    "    sharex=\"col\",\n",
    "    sharey=\"row\",\n",
    "    figsize=(width, height),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "\n",
    "for plot in zip(subplots, images):\n",
    "    ax = plot[0]\n",
    "    image = plot[1]\n",
    "    rgb_axes = show(image['ndvi'], \n",
    "                    transform=image['transform_window'], \n",
    "                    ax=ax[0], \n",
    "                    alpha=.75,\n",
    "                    cmap=\"RdYlGn\", \n",
    "                    title=image[\"date\"])\n",
    "    rgb_axes.ticklabel_format(style ='plain') # show full y-coords\n",
    "\n",
    "    show(image['rgb'], transform=image['transform_window'], ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable 3: `image-plots.png`\n",
    "\n",
    "Save a screenshot of part of the output of the image plots above and save it as `image-plots.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Clipping rasters by polygons\n",
    "\n",
    "Let's load up `geopandas` and extract some pixel data based on some polygons I drew of the neighborhood around Agua Caliente Park in Tucson, AZ. Our imagery is in EPSG:32612 so we will automatically reproject the geojson (which is always in lat/long; WGS84) using the `.to_crs()` function og `geopandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas \n",
    "\n",
    "fields = geopandas.read_file('neighborhood_samples.geojson').to_crs(epsg=32612)\n",
    "\n",
    "fields.head()\n",
    "fields.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the vectors over the image. We will share an axes object or else they will be written in separate graphs or one will overwrite (and erase) the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "\n",
    "bbox = [-110.74772571639987, 32.270431012618026, -110.70996215904789, 32.29386169894274]\n",
    "\n",
    "rgb_axes = show(images[0]['rgb'], \n",
    "                transform=images[0]['transform_window'], \n",
    "                ax=ax,\n",
    "                alpha=.75,\n",
    "                cmap=\"RdYlGn\", \n",
    "                title=\"Veg Types\")\n",
    "fields.boundary.plot(ax=ax, color='skyblue', linewidth=4)\n",
    "# ax.set_xlim(left=bbox[0], right=bbox[2])\n",
    "# ax.set_ylim(bottom=bbox[1], top=bbox[3])\n",
    "rgb_axes.ticklabel_format(style ='plain') # show full y-coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable 4 - `fields.png`\n",
    "\n",
    "Take a screenshot of the fgure above showing the polygon boundaries over the imagery.\n",
    "\n",
    "Next we will extract the imagery data within a polygon. Let's define a helper function that will utilize `rasterio`'s `features.geometry_mask()` function to clip rasters by polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.ma as ma\n",
    "from rasterio import features\n",
    "\n",
    "\n",
    "def mask_ndvi_by_field(image, field_geom):\n",
    "    \"\"\"\n",
    "    returns a numpy mask\n",
    "    \"\"\"\n",
    "    mask = features.geometry_mask(field_geom, \n",
    "                                out_shape=(image['ndvi'].shape[0],  image['ndvi'].shape[1]),\n",
    "                                transform=image['transform_window'], \n",
    "                                all_touched=False, \n",
    "                                invert=False)\n",
    "    ndvi_masked = ma.masked_array(image['ndvi'], mask)\n",
    "    return ndvi_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that those are defined let's run that function for every feature in the polygon dataset _for every image_. We will iterate over all images and, for each image, iterate over all polygon features. For each of those will will mask the NDVI by field to basically create a new band for each of the images that contains the NDVI only for the polygon areas intersecting the original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    ndvi_fields = {}\n",
    "    \n",
    "    for index, row in fields.iterrows():\n",
    "        field_mask = mask_ndvi_by_field(image, row.geometry)\n",
    "        ndvi_fields[row.area] = field_mask\n",
    "        image['ndvi_fields'] = ndvi_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at what you've created, using `images[0]` (the first one in our list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "show(images[0]['rgb'], transform=image['transform_window'], ax=ax, alpha=.50)\n",
    "        \n",
    "for field_id, field_ndvi in images[0]['ndvi_fields'].items():\n",
    "    rgb_axes= show(field_ndvi, transform=image['transform_window'],\n",
    "         ax=ax,\n",
    "         cmap=\"RdYlGn\", \n",
    "         vmin=-1, \n",
    "         vmax=1, \n",
    "         title=f\"NDVI Masked by Fields of Interest ({images[0]['date']})\")\n",
    "    \n",
    "rgb_axes.ticklabel_format(style ='plain') # show full y-coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: NDVI Time Series \n",
    "\n",
    "Finally we are going to calculate the average NDVI within one of the polygons over a lengthy time period.\n",
    "\n",
    "First we will re-search but for a longer time period. This is largely a copy-paste from earlier in this notebook but expediting the imagery for having NDVI for the full time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The date range for mapping NDVI overtime\n",
    "date_range = \"2020-01-01/2021-12-31\"\n",
    "\n",
    "long_series_images= []\n",
    "items = image_search(bbox, date_range, 5)\n",
    "items.summary()\n",
    "for item in items:\n",
    "    \n",
    "    # Refs to long_series_images\n",
    "    red = item.asset(\"red\")[\"href\"]\n",
    "    nir = item.asset(\"nir\")[\"href\"]\n",
    "    rgb = item.asset(\"visual\")[\"href\"]\n",
    "    date = item.date.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    # Streamed pixels within bbox\n",
    "    red_subset, transform_window = range_request(red, bbox)\n",
    "    nir_subset, transform_window = range_request(nir, bbox)\n",
    "    rgb_subset, transform_window = range_request(rgb, bbox)\n",
    "\n",
    "    # Calculate NDVI\n",
    "    ndvi_subset = (nir_subset.astype(float) - red_subset.astype(float)) / (\n",
    "        nir_subset + red_subset\n",
    "    )\n",
    "    \n",
    "    # Store the data for further processing\n",
    "    long_series_images.append(\n",
    "        {\"date\": date, \"rgb\": rgb_subset, \"ndvi\": ndvi_subset,'transform_window': transform_window}\n",
    "    )\n",
    "\n",
    "# reverse list as to be oldest to newest\n",
    "long_series_images.reverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "import matplotlib as mpl\n",
    "\n",
    "# compute the number of rows and columns\n",
    "n_plots = len(long_series_images)\n",
    "n_cols = int(np.sqrt(n_plots))\n",
    "n_rows = int(np.ceil(n_plots / n_cols))\n",
    "\n",
    "\n",
    "# setup the plot\n",
    "scale = max(n_cols, n_rows)\n",
    "fig = plt.figure(figsize=(5 * scale, 5 * scale))\n",
    "grid = gridspec.GridSpec(n_rows, n_cols, fig, wspace=0.4)\n",
    "\n",
    "\n",
    "# iterate through each subplot and plot each set of data\n",
    "for i in range(n_plots):\n",
    "    ax = fig.add_subplot(grid[i])\n",
    "    axes_subplot = show(images[i]['rgb'],\n",
    "                        transform=transform_window, \n",
    "                        ax=ax,  \n",
    "                        alpha=.65, \n",
    "                        title = images[i]['date'] )\n",
    "    \n",
    "    # plot the field data\n",
    "    for field_id, field_ndvi in images[i]['ndvi_fields'].items():\n",
    "        im = show(field_ndvi, transform=transform_window,\n",
    "             ax=ax,\n",
    "             cmap=\"RdYlGn\", \n",
    "             vmin=-1, \n",
    "             vmax=1, \n",
    "             )\n",
    "    axes_subplot.ticklabel_format(style ='plain') # show full y-coords\n",
    "    \n",
    "\n",
    "# Add custom color bar\n",
    "mpl.cm.cool\n",
    "norm = mpl.colors.Normalize(vmin=-1, vmax=1)\n",
    "\n",
    "fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=\"RdYlGn\"),\n",
    "             ax=grid.figure.get_axes() , orientation='vertical', label='NDVI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally... This is where we graph the NDVI over one of our polygon features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use geopandas `loc` to select the field where area name == riparin\n",
    "riparian = fields.loc[fields['area'] == 'riparian']\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(12,12))\n",
    "    \n",
    "rgb_axes = show(images[0]['rgb'], \n",
    "                transform=image['transform_window'], \n",
    "                ax=ax,\n",
    "                alpha=.75,\n",
    "                cmap=\"RdYlGn\", \n",
    "                title=\"Field 6\")\n",
    "fields.boundary.plot(ax=ax, color='skyblue', linewidth=4)\n",
    "riparian.boundary.plot(ax=ax, color='yellow', linewidth=6)                             \n",
    "rgb_axes.ticklabel_format(style ='plain') # show full y-coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable 5 - `ndvi-time-series.png`\n",
    "\n",
    "Save a screenshot of the time series graph above as `ndvi-time-series.png`\n",
    "\n",
    "## Final Deliverables\n",
    "Submit an open pull request from the `rasterio` branch to be merged with `master` containing these 5 files. Do not merge your pull request. \n",
    "- `stac-items.png`\n",
    "- `image-numpy.png`\n",
    "- `image-plots.png`\n",
    "- `fields.png`\n",
    "- `ndvi-time-series.png`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('geo-python-38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a786b2465b8d4a226d630ddf65f046caba60f2354367aac63bf9534d7fd32d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
